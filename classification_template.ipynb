{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AM1rcxnH0Pr"
      },
      "source": [
        "# Classification template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz19ErUVG334"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHVuHBwlGwQT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns   #visualisation\n",
        "import matplotlib.pyplot as plt    #visualisation\n",
        "%matplotlib inline\n",
        "#to display the plots immediatedly below the code\n",
        "sns.set(color_codes=True)\n",
        "#to enable us to use shorthand color codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcYk-5ZJEgb"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-FPUdPkJJDW"
      },
      "source": [
        "**Read dataset from drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcw_ULRDIIFw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7sFI_9gJTBl"
      },
      "outputs": [],
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq3mVHUzJbZn"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('drive/My Drive/datasets/(dataset_name)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZs9Us2xJ9ku"
      },
      "source": [
        "**Read dataset from github**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Klhn1UqJyY9"
      },
      "outputs": [],
      "source": [
        "#pd.read_csv('github link')\n",
        "data=pd.read_csv('https://raw.githubusercontent.com/amankharwal/Website-data/master/IRIS.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjxXL0gaKXAn"
      },
      "source": [
        "**Import and read excel data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlVDSzdWKu2_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QC2tJDjXK1-J"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "data=pd.read_excel(io.BytesIO(uploaded['(file_name).xlsx']))\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpmUn9rTMYJP"
      },
      "source": [
        "## Exploratory data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGLnLw-kLxXD"
      },
      "outputs": [],
      "source": [
        "data.head() #to show the first five entries in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsX-fWiOM1WT"
      },
      "outputs": [],
      "source": [
        "data.tail() #to show the last entries in the dataset  default=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLEwlUPKM4f1"
      },
      "outputs": [],
      "source": [
        "data.dtypes #check the types of data present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVYUSlOM7EW"
      },
      "outputs": [],
      "source": [
        "print(data.shape,'\\n')\n",
        "print(data.describe) #all the details about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv36h2sdNCmc"
      },
      "outputs": [],
      "source": [
        "data['column_name'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2i2_wP2QE8y"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSkShWl-NL84"
      },
      "source": [
        "**Dropping irrelevant columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ24fm4DNLk7"
      },
      "outputs": [],
      "source": [
        "data=data.drop(['Id'],axis=1)   #axis=1 implies we are dropping a coloumn\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym_5hCyTNUbj"
      },
      "source": [
        "**Renaming the rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXr5rY2xNXWO"
      },
      "outputs": [],
      "source": [
        "#this can be used to give the columns short alternative names so they are easier to access\n",
        "data=data.rename(columns={'SepalLengthCm':'SL','SepalWidthCm':'SW','PetalLengthCm':'PL','PetalWidthCm':'PW'})  #change the names according to the dataset imported\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFj7qRxnNoaV"
      },
      "source": [
        "**Dropping duplicate rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-Amoy-rNnjq"
      },
      "outputs": [],
      "source": [
        "if data.duplicated().any():\n",
        "  data=data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWiGfhjRCKmt"
      },
      "source": [
        "**Dropping null values**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data.isna(): Returns a DataFrame of the same shape as data, with True indicating the presence of a NaN in each cell.\n",
        "\n",
        "data.isna().any(): For each column, it checks if there are any True values (i.e., any NaN values). This results in a Series where each entry is True if the column contains at least one NaN.\n",
        "\n",
        "data.isna().any().any(): The second .any() checks across the entire Series of columns, returning True if any column has at least one missing value. Essentially, this checks if there's any missing value in the entire DataFrame.\n",
        "\n",
        "data.dropna(): If any missing value is found, dropna() is called to remove all rows containing NaNs."
      ],
      "metadata": {
        "id": "A2yO0BZxfHBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUM2a9mlCW_b"
      },
      "outputs": [],
      "source": [
        "if data.isna().any().any():\n",
        "  data=data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OR Run this to see what each function does**"
      ],
      "metadata": {
        "id": "BBi65-M-e_sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data.isna()"
      ],
      "metadata": {
        "id": "0LCJvdALeMC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.isna().any()"
      ],
      "metadata": {
        "id": "7mdqjgiIeQ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#na=data.isna().any().any()"
      ],
      "metadata": {
        "id": "2fJSdUr9eXz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if na:\n",
        "  data = data.dropna()"
      ],
      "metadata": {
        "id": "0gUqLrPLfEgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3CouToOIBb7"
      },
      "source": [
        "**Classifying the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzJiFL7fIAX_"
      },
      "outputs": [],
      "source": [
        "#finding the different values the target variable can take\n",
        "data['(Target_variable)'].unique() #replace target_variable with the actual name of the column you want to set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPPRhzq2IJZD"
      },
      "outputs": [],
      "source": [
        "data['(Target_variable)']=data['(Target_variable)'].replace({'(Target_variable_values)':1, '(Target_variable_values)':2, '(Target_variable_values)':3})\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgScF8a7LImA"
      },
      "source": [
        "## Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXH2eFE_LL1h"
      },
      "outputs": [],
      "source": [
        "print(data[\"(Target_variable)\"].value_counts())\n",
        "plot=sns.FacetGrid(data, hue=\"Species\", height=5).map(plt.scatter, \"(column_name)\", \"(column_name)\").add_legend()\n",
        "plot.set_xlabels('(label)') #set the label name\n",
        "plot.set_ylabels('(label)') #set the label name\n",
        "plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQynVxfNyn9"
      },
      "source": [
        "**Plotting different features against one another**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB3pBArtNxzh"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['PL'],data['Species'].astype('category').cat.codes,c=data['Species'].astype('category').cat.codes,cmap='rainbow')\n",
        "plt.xlabel('PetalLengthCm')\n",
        "plt.ylabel('Species')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx8HbwMsN3ws"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['SL'],data['Species'].astype('category').cat.codes,c=data['Species'].astype('category').cat.codes,cmap='rainbow')\n",
        "plt.xlabel('SepalLengthCm')\n",
        "plt.ylabel('Species')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PczDJ1XUN66w"
      },
      "source": [
        "## Test-Train-Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIgPUe-4DR7G"
      },
      "source": [
        "**This function randomly splits the data into the desired proportions (e.g., 80% for training, 20% for testing).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ-ab2w2OCkF"
      },
      "outputs": [],
      "source": [
        "#importing necessary modules and functions\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgHybQSMEWeP"
      },
      "outputs": [],
      "source": [
        "# Features and target variable\n",
        "x = data.drop('target_variable', axis=1) #enter target variable here and in the code below\n",
        "y = data['target_variable']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cGMrF02SDbOH"
      },
      "outputs": [],
      "source": [
        "## Split the data\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.2)\n",
        "x_train.count(),x_test.count(),y_train.count(),y_test.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BD5THt1nEbbf"
      },
      "outputs": [],
      "source": [
        "x_train.head(),y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyzbo8XyOEbm"
      },
      "source": [
        "## Model Selection and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-OUpBTQGO_S"
      },
      "source": [
        "**Different models have different strengths and weaknesses, and selecting the right one can significantly impact performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmaM7nCYGa5Q"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVUneuBOryq"
      },
      "source": [
        "Logistic regression is a supervised machine learning algorithm used for classification tasks where the goal is to predict the probability that an instance belongs to a given class or not. Logistic regression is a statistical algorithm which analyze the relationship between two data factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfg6RWP6I6sJ"
      },
      "source": [
        "import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa-aXz4fGOiX"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIpTiphYPm2F"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTKLCAhrOHxV"
      },
      "outputs": [],
      "source": [
        "#model = LogisticRegression(max_iter=300)    #uncomment this block if logistic regression is the model chosen\n",
        "#model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSD4lVnxOP5J"
      },
      "source": [
        "**Support Vector Machine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukef0_r3Op8k"
      },
      "source": [
        "Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression. Though we say regression problems as well it’s best suited for classification. The main objective of the SVM algorithm is to find the optimal hyperplane in an N-dimensional space that can separate the data points in different classes in the feature space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXMV0OzgNeG7"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm       #uncomment this block if svm is the model chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBgaccTXPy6k"
      },
      "outputs": [],
      "source": [
        "#model=svm.SVC(kernel='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOCYnhz5P2HD"
      },
      "outputs": [],
      "source": [
        "#model.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMk1pQzqQBNn"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrkSf61EEmit"
      },
      "source": [
        "A decision tree is a tree-like model used in machine learning and decision analysis to visually and explicitly represent decisions and their possible consequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFX6gY91P6Xv"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier    #uncomment this block if logistic regression is the model chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDhvElSJDxJu"
      },
      "outputs": [],
      "source": [
        "## Create a decision tree classifier\n",
        "#model = DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbP-YvOYD2nN"
      },
      "outputs": [],
      "source": [
        "## Train the classifier on the training data\n",
        "#model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANEqefUgExZf"
      },
      "source": [
        "## Model Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgK8EE2IHvho"
      },
      "source": [
        "### Decision Tree visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K-HzjMWIa9s"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree # Import plot_tree from sklearn.tree\n",
        "import matplotlib.pyplot as plt    # Import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrFyeo2XHy5C"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx8TNwXfH-Cm"
      },
      "outputs": [],
      "source": [
        "# Get feature and target column names\n",
        "feature_names = data.columns[:-1] # Assuming the last column is the target\n",
        "target_names = data['Species'].unique() # Replace 'target_column' with your actual target column name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pokUuoolKDgx"
      },
      "outputs": [],
      "source": [
        "plot_tree(model, feature_names=feature_names, class_names=target_names, filled=True, rounded=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzD4Xj3HKwct"
      },
      "source": [
        "### SVM Intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IGVCYEAK0p9"
      },
      "source": [
        "While plotting the decision function of classifiers for toy 2D datasets can help get an intuitive understanding of their respective expressive power, be aware that those intuitions don’t always generalize to more realistic high-dimensional problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu1lxKe6K5Fk"
      },
      "source": [
        "We only consider the first 2 features of this dataset:\n",
        "\n",
        "Sepal length\n",
        "\n",
        "Sepal width"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is an example and loads ,and works on, the iris dataset that is already available in sklearn library."
      ],
      "metadata": {
        "id": "KXFOMoOqVcFW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J68UXl8dPGHB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "## import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "## Take the first two features. We could avoid this by using a two-dim dataset\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# we create an instance of SVM and fit out data. We do not scale our\n",
        "# data since we want to plot the support vectors\n",
        "C = 1.0  # SVM regularization parameter\n",
        "models = (\n",
        "    svm.SVC(kernel=\"linear\", C=C),\n",
        "    svm.LinearSVC(C=C, max_iter=10000)\n",
        ")\n",
        "models = (clf.fit(X, y) for clf in models)\n",
        "\n",
        "# title for the plots\n",
        "titles = (\n",
        "    \"SVC with linear kernel\",\n",
        "    \"LinearSVC (linear kernel)\"\n",
        ")\n",
        "\n",
        "# Set-up 2x2 grid for plotting.\n",
        "fig, sub = plt.subplots(1, 2)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "X0, X1 = X[:, 0], X[:, 1]\n",
        "\n",
        "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        response_method=\"predict\",\n",
        "        cmap=plt.cm.coolwarm,\n",
        "        alpha=0.8,\n",
        "        ax=ax,\n",
        "        xlabel=iris.feature_names[0],\n",
        "        ylabel=iris.feature_names[1],\n",
        "    )\n",
        "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are working with a dataset that can be uploaded from various sources as shown above."
      ],
      "metadata": {
        "id": "r8m986wdVx7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RnZoclaxQDNS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets, svm\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "#taking the first two features\n",
        "X = data.iloc[:, :2]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# we create an instance of SVM and fit out data. We do not scale our\n",
        "# data since we want to plot the support vectors\n",
        "C = 1.0  # SVM regularization parameter\n",
        "models = (\n",
        "    svm.SVC(kernel=\"linear\", C=C),\n",
        "    svm.LinearSVC(C=C, max_iter=10000)\n",
        ")\n",
        "models = (clf.fit(X, y) for clf in models)\n",
        "\n",
        "# title for the plots\n",
        "titles = (\n",
        "    \"SVC with linear kernel\",\n",
        "    \"LinearSVC (linear kernel)\"\n",
        ")\n",
        "\n",
        "# Set-up 2x2 grid for plotting.\n",
        "fig, sub = plt.subplots(1, 2)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "X0, X1 = X.iloc[:, 0], X.iloc[:, 1]\n",
        "\n",
        "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        response_method=\"predict\",\n",
        "        cmap=plt.cm.coolwarm,\n",
        "        alpha=0.8,\n",
        "        ax=ax,\n",
        "        xlabel=(data.columns[0]),\n",
        "        ylabel=(data.columns[1]),\n",
        "    )\n",
        "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlKQgqFxH1MT"
      },
      "source": [
        "### Evaluation Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_SfBsveFQIo"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR-MBBAQEif5"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uhaEzmyFFO5o"
      },
      "outputs": [],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_VcGgY2TFZ_n"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation"
      ],
      "metadata": {
        "id": "VHQDN2tbguSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "# Perform 5-fold cross-validation\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Average cross-validation score:\", cv_scores.mean())"
      ],
      "metadata": {
        "id": "LuO3zaNngw20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yiJHhR0HRKV"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CYMhMPJFEpE"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxapkz2CTBl4"
      },
      "source": [
        "Precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEhJ_WA7TDEb"
      },
      "outputs": [],
      "source": [
        "precision = metrics.precision_score(y_test, y_pred, average='weighted') #for multi-class\n",
        "print(f\"Precision: {precision}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWSeBzf_TWx-"
      },
      "source": [
        "Recall(Sensitivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi40E5ZsTZ1i"
      },
      "outputs": [],
      "source": [
        "recall = metrics.recall_score(y_test, y_pred, average='weighted') #for multi-class\n",
        "print(f\"Recall: {recall}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV5f8O_QTkDW"
      },
      "source": [
        "F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyXRiSkKTl7t"
      },
      "outputs": [],
      "source": [
        "f1 = metrics.f1_score(y_test, y_pred, average='weighted') #for multi-class\n",
        "print(f\"F1-Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC Curve"
      ],
      "metadata": {
        "id": "fvl5CUQuiSOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Predict probabilities\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ChXm5WngiP8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6itxg51T0QQ"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe1-J9o2Fczm"
      },
      "outputs": [],
      "source": [
        "#confusion matrix summarizes the performance of a machine learning model ona set of test data\n",
        "c_matrix=confusion_matrix(y_test,y_pred)\n",
        "c_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHuxNpnIGS9K"
      },
      "source": [
        "We visualise it using a heat map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UthG4RqeF8zq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OpmUn9rTMYJP"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}